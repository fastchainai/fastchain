"""Chat model implementation."""
from typing import List, Optional, Dict, Any
from datetime import datetime

from langchain_core.prompts import PromptTemplate
from langchain_core.language_models import BaseLLM
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI

class ChatModel:
    """
    ChatModel implements conversation history management for chat-based interactions.
    """

    def __init__(self, model: Optional[BaseLLM] = None, conversation_history: List[str] = None):
        """
        Initialize a ChatModel instance.

        Args:
            model: An instance of LLM to process chat messages
            conversation_history: Initial conversation history
        """
        self.model = model or ChatOpenAI(temperature=0.7)
        self.conversation_history = conversation_history or []

        # Initialize the chain
        prompt = PromptTemplate.from_template("""
        Previous conversation:
        {history}

        Human: {message}
        Assistant: Let me help you with that.
        """)

        self.chain = (
            {"history": lambda x: "\n".join(self.conversation_history[-5:]),
             "message": RunnablePassthrough()}
            | prompt
            | self.model
            | StrOutputParser()
        )

    def validate_model(self) -> bool:
        """
        Validate that the ChatModel is correctly configured.

        Returns:
            bool: True if the model is valid, False otherwise
        """
        try:
            is_valid = isinstance(self.model, BaseLLM) and isinstance(self.conversation_history, list)
            return is_valid
        except Exception as e:
            print(f"Validation error: {str(e)}")
            return False

    def chat(self, message: str) -> str:
        """
        Process a chat message using the underlying chain.

        Args:
            message: The user's chat message

        Returns:
            str: The response generated by the chain
        """
        try:
            # Add user message to history
            self.conversation_history.append(f"User: {message}")

            # Process message
            if not self.validate_model():
                raise ValueError("Chat model not properly configured")

            # Generate response using the chain
            response = self.chain.invoke(message)

            # Add response to history
            self.conversation_history.append(f"Assistant: {response}")

            return response

        except Exception as e:
            print(f"Error processing chat message: {str(e)}")
            raise

    def get_conversation_history(self) -> List[str]:
        """Get the current conversation history."""
        return self.conversation_history.copy()

    def clear_conversation_history(self):
        """Clear the conversation history."""
        try:
            self.conversation_history.clear()
        except Exception as e:
            print(f"Error clearing conversation history: {str(e)}")
            raise